{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25515ac6-d10f-432f-a180-a63b22c3a973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8e07b2f-48ca-44f0-964b-f92704c45547",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor([[[1,2,3],\n",
    "                    [4,5,6]],\n",
    "                   [[10,11,12],\n",
    "                    [13,14,15]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "969bd65c-f5e8-4983-812f-1126a2544ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa8855a4-6192-4bb2-ab19-ce5312aeb2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = torch.tensor([[[-99,81,101],\n",
    "                    [-4,54,75]],\n",
    "                   [[108,-11,-12],\n",
    "                    [133,144,150]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f960a71-2ff0-43a4-ad30-98ef9733c296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a5de277-967c-4841-a8f9-7cfad6a4b098",
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = torch.tensor(4.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73ecbe4f-b65e-4111-a465-7d6ec6ded8d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0508d3-1608-458a-bfe8-140d5f986d0b",
   "metadata": {},
   "source": [
    "### Tensor can do arithmetic operations directly. That's the strength of tensor over pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "702b3369-75de-45cc-bad4-1211025aec82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -95.,  166.,  307.],\n",
       "         [ -12.,  274.,  454.]],\n",
       "\n",
       "        [[1084., -117., -140.],\n",
       "         [1733., 2020., 2254.]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = t1*t2 +t3\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88bae104-5f44-491a-9e07-67918a41b99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2b6fa5-446a-44cf-988e-1089a204dc61",
   "metadata": {},
   "source": [
    "### In torch.tensor you cannot make string array. It supports only numerical data, float. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f121ba86-800c-4742-b9cd-4b678e55e02d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m t4 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHello\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOK\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m t4\n",
      "\u001b[1;31mValueError\u001b[0m: too many dimensions 'str'"
     ]
    }
   ],
   "source": [
    "t4 = torch.tensor(['Hello','OK'])\n",
    "t4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "120d9106-6dc5-46a9-b299-c83953a03fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "150b7e67-ea30-40f9-bbfb-630f900a84ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input (temp,rainfall,humidity)\n",
    "inputs = np.array([[73.,67.,43.],\n",
    "                    [91.,88.,64.],\n",
    "                    [87.,134.,58.],\n",
    "                    [102.,43.,37.],\n",
    "                    [69.,96.,70.]],dtype=\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a8b92bb-43b2-4307-b1ab-a0e9a3d7979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Targets (apple, orange)\n",
    "targets = np.array([[56.,70.],\n",
    "                   [81.,101.],\n",
    "                   [119.,133.],\n",
    "                    [22.,37.],\n",
    "                    [103.,119.]], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a0586cb-7dad-4f17-8d67-d0b6470c5849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.]])\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.from_numpy(inputs)\n",
    "target_tensor = torch.from_numpy(targets)\n",
    "print(input_tensor)\n",
    "print(target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42e61dc3-15a5-45d7-a95f-9907cc65b629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f05e862c-819c-4baf-bdba-d3de159ca13e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20592d4-5566-45b3-91f5-3bafd1779dd9",
   "metadata": {},
   "source": [
    " ### How linear algebra and cost function plays in linear regression\n",
    " y_orange = w11 * x1 + w12 * x2 + w13 *x3 +b1\n",
    " \n",
    " \n",
    " \n",
    " y_apple = w21 * x1 + w22 * x2 + w23 * x3 +b2\n",
    " \n",
    " y=AX+B\n",
    " \n",
    " \n",
    " A = [w11,w12,w13\n",
    "   \n",
    "    w21,w22,w23]\n",
    " \n",
    " \n",
    " X = [X1,\n",
    " \n",
    "    X2,\n",
    "      \n",
    "    X3]\n",
    "      \n",
    "      \n",
    "      \n",
    "B = [b1,\n",
    "\n",
    "    b2]\n",
    "     \n",
    "     \n",
    "This is how linear regression works "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66cf87fe-c475-40d4-a08f-366836152171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4926,  0.1573, -0.3251],\n",
      "        [ 0.3469,  1.3503,  0.5836]], requires_grad=True)\n",
      "tensor([-0.3269, -1.4682], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "w = torch.randn(2,3,requires_grad=True)\n",
    "b = torch.randn(2,requires_grad=True)\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed7422e-8eeb-4159-86df-a2dde090e57c",
   "metadata": {},
   "source": [
    "### Model creation\n",
    "\n",
    "    @ represent matrix multiplication\n",
    "    w.t() represent the transpose of a given matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43c4c254-c9ba-40ef-b924-c98b069565a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x):\n",
    "    return x @ w.t() + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26b72eea-9ce5-4aba-b108-67a235b3fb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[105.1927, 139.4232],\n",
      "        [128.5359, 186.2803],\n",
      "        [131.7514, 243.5040],\n",
      "        [146.6535, 113.5755],\n",
      "        [ 95.0066, 192.9519]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "preds = model(input_tensor)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2220fd6-65f7-4d75-84f2-4403c3143186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "print(target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3873c9c-f715-4a91-8f42-5d6944de4ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5608.0693, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dif = preds - target_tensor\n",
    "torch.sum(dif*dif)/dif.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bb762d-0c6f-44f1-a9ca-7accb5a0a61c",
   "metadata": {},
   "source": [
    "Mean Square Error = 11270.5098"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a456e3f1-419b-457f-9be2-8233fe6ffcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(t1,t2):\n",
    "    dif = t1 - t2\n",
    "    return torch.sum(dif*dif) / dif.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04623a1a-bf14-4b0a-a4f4-d2a13cf059c7",
   "metadata": {},
   "source": [
    "Computing mse using the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ed5a23e-762e-40c2-b027-b80bd186e8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5608.0693, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Compute loss\n",
    "loss = mse(preds,target_tensor)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f35ab2b-5e8b-474c-8876-7ac7892ebd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute gradients\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f317421b-5690-4a83-b0e5-c9b8b026eb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4926,  0.1573, -0.3251],\n",
      "        [ 0.3469,  1.3503,  0.5836]], requires_grad=True)\n",
      "tensor([[4237.8618, 2756.0964, 1989.9603],\n",
      "        [7071.1255, 7471.1372, 4572.4590]])\n"
     ]
    }
   ],
   "source": [
    "print(w)\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1023d12a-85ce-47d6-aea8-9b3727d0c9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[ 1.4926,  0.1573, -0.3251],\n",
      "        [ 0.3469,  1.3503,  0.5836]], requires_grad=True)\n",
      "tensor([0., 0.])\n",
      "tensor([-0.3269, -1.4682], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "w.grad.zero_()\n",
    "b.grad.zero_()\n",
    "print(w.grad)\n",
    "print(w)\n",
    "print(b.grad)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f09319-fced-4dce-8efe-bff5956f8106",
   "metadata": {},
   "source": [
    "## Train the model using gradient descent\n",
    "\n",
    "As seen above, we reduce the loss and improve our model using the gradient descent optimization algorithm. Thus, we can _train_ the model using the following steps:\n",
    "\n",
    "1. Generate predictions\n",
    "\n",
    "2. Calculate the loss\n",
    "\n",
    "3. Compute gradients w.r.t the weights and biases\n",
    "\n",
    "4. Adjust the weights by subtracting a small quantity proportional to the gradient\n",
    "\n",
    "5. Reset the gradients to zero\n",
    "\n",
    "Let's implement the above step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83db9167-151c-4b31-82ce-790903330b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[105.1927, 139.4232],\n",
      "        [128.5359, 186.2803],\n",
      "        [131.7514, 243.5040],\n",
      "        [146.6535, 113.5755],\n",
      "        [ 95.0066, 192.9519]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "preds = model(input_tensor)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1de3edcc-ac1a-4f50-b6e2-29b2cc7cc88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5608.0693, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = mse(preds, target_tensor)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc0ba487-f62a-451d-bafe-8637bcae84ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4237.8618, 2756.0964, 1989.9603],\n",
      "        [7071.1255, 7471.1372, 4572.4590]])\n",
      "tensor([45.2280, 83.1470])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3dae7d4c-b810-40af-a1ce-0080a761e9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    w -= w.grad * 1e-5\n",
    "    b -= b.grad * 1e-5\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "566740d6-1bcb-4c51-8629-455a8c8a2abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5346, grad_fn=<DivBackward0>)\n",
      "tensor(0.5345, grad_fn=<DivBackward0>)\n",
      "tensor(0.5344, grad_fn=<DivBackward0>)\n",
      "tensor(0.5343, grad_fn=<DivBackward0>)\n",
      "tensor(0.5343, grad_fn=<DivBackward0>)\n",
      "tensor(0.5342, grad_fn=<DivBackward0>)\n",
      "tensor(0.5341, grad_fn=<DivBackward0>)\n",
      "tensor(0.5340, grad_fn=<DivBackward0>)\n",
      "tensor(0.5340, grad_fn=<DivBackward0>)\n",
      "tensor(0.5339, grad_fn=<DivBackward0>)\n",
      "tensor(0.5338, grad_fn=<DivBackward0>)\n",
      "tensor(0.5337, grad_fn=<DivBackward0>)\n",
      "tensor(0.5336, grad_fn=<DivBackward0>)\n",
      "tensor(0.5336, grad_fn=<DivBackward0>)\n",
      "tensor(0.5335, grad_fn=<DivBackward0>)\n",
      "tensor(0.5334, grad_fn=<DivBackward0>)\n",
      "tensor(0.5333, grad_fn=<DivBackward0>)\n",
      "tensor(0.5333, grad_fn=<DivBackward0>)\n",
      "tensor(0.5332, grad_fn=<DivBackward0>)\n",
      "tensor(0.5331, grad_fn=<DivBackward0>)\n",
      "tensor(0.5330, grad_fn=<DivBackward0>)\n",
      "tensor(0.5330, grad_fn=<DivBackward0>)\n",
      "tensor(0.5329, grad_fn=<DivBackward0>)\n",
      "tensor(0.5328, grad_fn=<DivBackward0>)\n",
      "tensor(0.5327, grad_fn=<DivBackward0>)\n",
      "tensor(0.5327, grad_fn=<DivBackward0>)\n",
      "tensor(0.5326, grad_fn=<DivBackward0>)\n",
      "tensor(0.5325, grad_fn=<DivBackward0>)\n",
      "tensor(0.5324, grad_fn=<DivBackward0>)\n",
      "tensor(0.5324, grad_fn=<DivBackward0>)\n",
      "tensor(0.5323, grad_fn=<DivBackward0>)\n",
      "tensor(0.5322, grad_fn=<DivBackward0>)\n",
      "tensor(0.5321, grad_fn=<DivBackward0>)\n",
      "tensor(0.5321, grad_fn=<DivBackward0>)\n",
      "tensor(0.5320, grad_fn=<DivBackward0>)\n",
      "tensor(0.5319, grad_fn=<DivBackward0>)\n",
      "tensor(0.5318, grad_fn=<DivBackward0>)\n",
      "tensor(0.5318, grad_fn=<DivBackward0>)\n",
      "tensor(0.5317, grad_fn=<DivBackward0>)\n",
      "tensor(0.5316, grad_fn=<DivBackward0>)\n",
      "tensor(0.5315, grad_fn=<DivBackward0>)\n",
      "tensor(0.5315, grad_fn=<DivBackward0>)\n",
      "tensor(0.5314, grad_fn=<DivBackward0>)\n",
      "tensor(0.5313, grad_fn=<DivBackward0>)\n",
      "tensor(0.5313, grad_fn=<DivBackward0>)\n",
      "tensor(0.5312, grad_fn=<DivBackward0>)\n",
      "tensor(0.5311, grad_fn=<DivBackward0>)\n",
      "tensor(0.5310, grad_fn=<DivBackward0>)\n",
      "tensor(0.5310, grad_fn=<DivBackward0>)\n",
      "tensor(0.5309, grad_fn=<DivBackward0>)\n",
      "tensor(0.5308, grad_fn=<DivBackward0>)\n",
      "tensor(0.5307, grad_fn=<DivBackward0>)\n",
      "tensor(0.5307, grad_fn=<DivBackward0>)\n",
      "tensor(0.5306, grad_fn=<DivBackward0>)\n",
      "tensor(0.5305, grad_fn=<DivBackward0>)\n",
      "tensor(0.5305, grad_fn=<DivBackward0>)\n",
      "tensor(0.5304, grad_fn=<DivBackward0>)\n",
      "tensor(0.5303, grad_fn=<DivBackward0>)\n",
      "tensor(0.5302, grad_fn=<DivBackward0>)\n",
      "tensor(0.5302, grad_fn=<DivBackward0>)\n",
      "tensor(0.5301, grad_fn=<DivBackward0>)\n",
      "tensor(0.5300, grad_fn=<DivBackward0>)\n",
      "tensor(0.5300, grad_fn=<DivBackward0>)\n",
      "tensor(0.5299, grad_fn=<DivBackward0>)\n",
      "tensor(0.5298, grad_fn=<DivBackward0>)\n",
      "tensor(0.5298, grad_fn=<DivBackward0>)\n",
      "tensor(0.5297, grad_fn=<DivBackward0>)\n",
      "tensor(0.5296, grad_fn=<DivBackward0>)\n",
      "tensor(0.5295, grad_fn=<DivBackward0>)\n",
      "tensor(0.5295, grad_fn=<DivBackward0>)\n",
      "tensor(0.5294, grad_fn=<DivBackward0>)\n",
      "tensor(0.5293, grad_fn=<DivBackward0>)\n",
      "tensor(0.5293, grad_fn=<DivBackward0>)\n",
      "tensor(0.5292, grad_fn=<DivBackward0>)\n",
      "tensor(0.5291, grad_fn=<DivBackward0>)\n",
      "tensor(0.5291, grad_fn=<DivBackward0>)\n",
      "tensor(0.5290, grad_fn=<DivBackward0>)\n",
      "tensor(0.5289, grad_fn=<DivBackward0>)\n",
      "tensor(0.5289, grad_fn=<DivBackward0>)\n",
      "tensor(0.5288, grad_fn=<DivBackward0>)\n",
      "tensor(0.5287, grad_fn=<DivBackward0>)\n",
      "tensor(0.5287, grad_fn=<DivBackward0>)\n",
      "tensor(0.5286, grad_fn=<DivBackward0>)\n",
      "tensor(0.5285, grad_fn=<DivBackward0>)\n",
      "tensor(0.5285, grad_fn=<DivBackward0>)\n",
      "tensor(0.5284, grad_fn=<DivBackward0>)\n",
      "tensor(0.5283, grad_fn=<DivBackward0>)\n",
      "tensor(0.5283, grad_fn=<DivBackward0>)\n",
      "tensor(0.5282, grad_fn=<DivBackward0>)\n",
      "tensor(0.5281, grad_fn=<DivBackward0>)\n",
      "tensor(0.5280, grad_fn=<DivBackward0>)\n",
      "tensor(0.5280, grad_fn=<DivBackward0>)\n",
      "tensor(0.5279, grad_fn=<DivBackward0>)\n",
      "tensor(0.5279, grad_fn=<DivBackward0>)\n",
      "tensor(0.5278, grad_fn=<DivBackward0>)\n",
      "tensor(0.5277, grad_fn=<DivBackward0>)\n",
      "tensor(0.5277, grad_fn=<DivBackward0>)\n",
      "tensor(0.5276, grad_fn=<DivBackward0>)\n",
      "tensor(0.5275, grad_fn=<DivBackward0>)\n",
      "tensor(0.5275, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    preds = model(input_tensor)\n",
    "    loss = mse(preds, target_tensor)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= w.grad * 1e-5\n",
    "        b -= b.grad * 1e-5\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d589fdf1-4898-46a9-97a7-96a987e2d9d6",
   "metadata": {},
   "source": [
    "### Now implementing linear regression using pytorch's inbuilt function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7bc4783a-f567-4057-b122-a01d10e2771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bbc1ef78-a4d2-4865-91e9-be1fcd33bd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70], \n",
    "                   [74, 66, 43], \n",
    "                   [91, 87, 65], \n",
    "                   [88, 134, 59], \n",
    "                   [101, 44, 37], \n",
    "                   [68, 96, 71], \n",
    "                   [73, 66, 44], \n",
    "                   [92, 87, 64], \n",
    "                   [87, 135, 57], \n",
    "                   [103, 43, 36], \n",
    "                   [68, 97, 70]], \n",
    "                  dtype='float32')\n",
    "\n",
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119],\n",
    "                    [57, 69], \n",
    "                    [80, 102], \n",
    "                    [118, 132], \n",
    "                    [21, 38], \n",
    "                    [104, 118], \n",
    "                    [57, 69], \n",
    "                    [82, 100], \n",
    "                    [118, 134], \n",
    "                    [20, 38], \n",
    "                    [102, 120]], \n",
    "                   dtype='float32')\n",
    "\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "37b34c96-2628-4140-979e-7a9aabcd5bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 73.,  67.,  43.],\n",
       "        [ 91.,  88.,  64.],\n",
       "        [ 87., 134.,  58.],\n",
       "        [102.,  43.,  37.],\n",
       "        [ 69.,  96.,  70.],\n",
       "        [ 74.,  66.,  43.],\n",
       "        [ 91.,  87.,  65.],\n",
       "        [ 88., 134.,  59.],\n",
       "        [101.,  44.,  37.],\n",
       "        [ 68.,  96.,  71.],\n",
       "        [ 73.,  66.,  44.],\n",
       "        [ 92.,  87.,  64.],\n",
       "        [ 87., 135.,  57.],\n",
       "        [103.,  43.,  36.],\n",
       "        [ 68.,  97.,  70.]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09adc8e0-b23d-4031-b536-0e2d5fc8ccc8",
   "metadata": {},
   "source": [
    "### To load the data we use Tensor dataset which allows you access to rows of inputs and targets as tuples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "05630ec5-fe66-4e52-81f3-8b406543f426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "63dcb7f1-76fc-4778-bf3f-08ba70b2cffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 73.,  67.,  43.],\n",
       "         [ 91.,  88.,  64.],\n",
       "         [ 87., 134.,  58.],\n",
       "         [102.,  43.,  37.]]),\n",
       " tensor([[ 56.,  70.],\n",
       "         [ 81., 101.],\n",
       "         [119., 133.],\n",
       "         [ 22.,  37.]]))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = TensorDataset(inputs,targets)\n",
    "train_ds[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c247827-984a-4709-9b07-5c8766a74f65",
   "metadata": {},
   "source": [
    "### DataLoader is used to load the data into mini batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "02a37915-01e1-44e6-94e6-9145d2856dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "485794f3-15de-49dc-8bec-cc5b9da02931",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds,batch_size,shuffle = True)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c351b1d4-e2b0-4687-9080-852a7f7596bb",
   "metadata": {},
   "source": [
    "The dataloader is typically used in a for-loop. Let's took an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "54d7e22b-883e-4dce-878e-c7cd6831c8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 74.,  66.,  43.],\n",
      "        [103.,  43.,  36.],\n",
      "        [ 73.,  67.,  43.],\n",
      "        [ 68.,  96.,  71.],\n",
      "        [101.,  44.,  37.]])\n",
      "tensor([[ 57.,  69.],\n",
      "        [ 20.,  38.],\n",
      "        [ 56.,  70.],\n",
      "        [104., 118.],\n",
      "        [ 21.,  38.]])\n",
      "\n",
      "\n",
      "tensor([[73., 66., 44.],\n",
      "        [68., 97., 70.],\n",
      "        [92., 87., 64.],\n",
      "        [69., 96., 70.],\n",
      "        [91., 88., 64.]])\n",
      "tensor([[ 57.,  69.],\n",
      "        [102., 120.],\n",
      "        [ 82., 100.],\n",
      "        [103., 119.],\n",
      "        [ 81., 101.]])\n",
      "\n",
      "\n",
      "tensor([[102.,  43.,  37.],\n",
      "        [ 87., 135.,  57.],\n",
      "        [ 91.,  87.,  65.],\n",
      "        [ 88., 134.,  59.],\n",
      "        [ 87., 134.,  58.]])\n",
      "tensor([[ 22.,  37.],\n",
      "        [118., 134.],\n",
      "        [ 80., 102.],\n",
      "        [118., 132.],\n",
      "        [119., 133.]])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_dl:\n",
    "    print(x)\n",
    "    print(y)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a252e375-1a69-4d53-a8eb-d290e4847e91",
   "metadata": {},
   "source": [
    "### Using nn.Linear you can directly create a linear regression model object instead of manually creating a model function each and every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e9b40a69-1564-430c-abd2-0f43764321ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.5540,  0.4187, -0.3194],\n",
      "        [ 0.5036,  0.4312, -0.3408]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0283, 0.5620], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Linear(3,2)\n",
    "print(model.weight)\n",
    "print(model.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020abf66-fd13-41a3-940c-f222a67abefc",
   "metadata": {},
   "source": [
    "PyTorch models also have a helpful `.parameters` method, which returns a list containing all the weights and bias matrices present in the model. For our linear regression model, we have one weight matrix and one bias matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2b1403d0-f17a-4335-9f8e-ac73528d036e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.5540,  0.4187, -0.3194],\n",
       "         [ 0.5036,  0.4312, -0.3408]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.0283, 0.5620], requires_grad=True)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "233ab6fc-cf09-4703-93ee-568582afbe12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-26.0937,  51.5618],\n",
       "        [-33.9799,  62.5253],\n",
       "        [-10.5879,  82.3892],\n",
       "        [-50.2917,  57.8637],\n",
       "        [-20.3589,  52.8501],\n",
       "        [-27.0664,  51.6342],\n",
       "        [-34.7180,  61.7533],\n",
       "        [-11.4613,  82.5520],\n",
       "        [-49.3190,  57.7912],\n",
       "        [-20.1243,  52.0057],\n",
       "        [-26.8318,  50.7898],\n",
       "        [-34.9526,  62.5978],\n",
       "        [ -9.8499,  83.1611],\n",
       "        [-50.5263,  58.7081],\n",
       "        [-19.3862,  52.7777]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd841779-e3de-474e-a85f-0630b4ca15a3",
   "metadata": {},
   "source": [
    "## Loss Function\n",
    "\n",
    "Instead of defining a loss function manually, we can use the built-in loss function `mse_loss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "22a26a5c-cb5c-4d2e-bc18-8c595dc6729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "loss_fn = F.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f2151d45-8817-4487-a432-3eecc77a6c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6628.8115, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = loss_fn(model(inputs),targets)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e15c1a-1470-46b8-9941-c121c1ad25bf",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "\n",
    "Instead of manually manipulating the model's weights & biases using gradients, we can use the optimizer `optim.SGD`. SGD is short for \"stochastic gradient descent\". The term _stochastic_ indicates that samples are selected in random batches instead of as a single group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5ba819fe-2b70-4eab-b620-0d84ed08cbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining optimizer\n",
    "opt = torch.optim.SGD(model.parameters(),lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "21ba3a8b-9f4f-49c1-b58e-f5e7af4160aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1651.3601\n",
      "Epoch [2/100], Loss: 517.9539\n",
      "Epoch [3/100], Loss: 582.2565\n",
      "Epoch [4/100], Loss: 390.6573\n",
      "Epoch [5/100], Loss: 28.5129\n",
      "Epoch [6/100], Loss: 444.6581\n",
      "Epoch [7/100], Loss: 424.7068\n",
      "Epoch [8/100], Loss: 257.3707\n",
      "Epoch [9/100], Loss: 126.6385\n",
      "Epoch [10/100], Loss: 238.9079\n",
      "Epoch [11/100], Loss: 466.9403\n",
      "Epoch [12/100], Loss: 372.1020\n",
      "Epoch [13/100], Loss: 235.8814\n",
      "Epoch [14/100], Loss: 512.0754\n",
      "Epoch [15/100], Loss: 245.7769\n",
      "Epoch [16/100], Loss: 241.6556\n",
      "Epoch [17/100], Loss: 369.8845\n",
      "Epoch [18/100], Loss: 295.5966\n",
      "Epoch [19/100], Loss: 109.0165\n",
      "Epoch [20/100], Loss: 307.4822\n",
      "Epoch [21/100], Loss: 211.9629\n",
      "Epoch [22/100], Loss: 130.9624\n",
      "Epoch [23/100], Loss: 241.7461\n",
      "Epoch [24/100], Loss: 297.9491\n",
      "Epoch [25/100], Loss: 198.4643\n",
      "Epoch [26/100], Loss: 269.3156\n",
      "Epoch [27/100], Loss: 131.0230\n",
      "Epoch [28/100], Loss: 19.2312\n",
      "Epoch [29/100], Loss: 176.7535\n",
      "Epoch [30/100], Loss: 91.4471\n",
      "Epoch [31/100], Loss: 234.4617\n",
      "Epoch [32/100], Loss: 27.8532\n",
      "Epoch [33/100], Loss: 225.0353\n",
      "Epoch [34/100], Loss: 224.0615\n",
      "Epoch [35/100], Loss: 88.0445\n",
      "Epoch [36/100], Loss: 169.9313\n",
      "Epoch [37/100], Loss: 164.9056\n",
      "Epoch [38/100], Loss: 141.2479\n",
      "Epoch [39/100], Loss: 208.3196\n",
      "Epoch [40/100], Loss: 216.5326\n",
      "Epoch [41/100], Loss: 228.4098\n",
      "Epoch [42/100], Loss: 150.6190\n",
      "Epoch [43/100], Loss: 183.4826\n",
      "Epoch [44/100], Loss: 69.9986\n",
      "Epoch [45/100], Loss: 128.1643\n",
      "Epoch [46/100], Loss: 120.5770\n",
      "Epoch [47/100], Loss: 111.0772\n",
      "Epoch [48/100], Loss: 112.8761\n",
      "Epoch [49/100], Loss: 113.8187\n",
      "Epoch [50/100], Loss: 169.2624\n",
      "Epoch [51/100], Loss: 64.9564\n",
      "Epoch [52/100], Loss: 105.0420\n",
      "Epoch [53/100], Loss: 125.6078\n",
      "Epoch [54/100], Loss: 106.0760\n",
      "Epoch [55/100], Loss: 73.0832\n",
      "Epoch [56/100], Loss: 130.8570\n",
      "Epoch [57/100], Loss: 123.2084\n",
      "Epoch [58/100], Loss: 175.9035\n",
      "Epoch [59/100], Loss: 112.1022\n",
      "Epoch [60/100], Loss: 141.0003\n",
      "Epoch [61/100], Loss: 98.6917\n",
      "Epoch [62/100], Loss: 137.8016\n",
      "Epoch [63/100], Loss: 129.3058\n",
      "Epoch [64/100], Loss: 104.9851\n",
      "Epoch [65/100], Loss: 85.1706\n",
      "Epoch [66/100], Loss: 52.0476\n",
      "Epoch [67/100], Loss: 49.4363\n",
      "Epoch [68/100], Loss: 120.3413\n",
      "Epoch [69/100], Loss: 69.1589\n",
      "Epoch [70/100], Loss: 82.1156\n",
      "Epoch [71/100], Loss: 122.3360\n",
      "Epoch [72/100], Loss: 54.4985\n",
      "Epoch [73/100], Loss: 71.6482\n",
      "Epoch [74/100], Loss: 86.5846\n",
      "Epoch [75/100], Loss: 94.5915\n",
      "Epoch [76/100], Loss: 44.0231\n",
      "Epoch [77/100], Loss: 109.8988\n",
      "Epoch [78/100], Loss: 56.4770\n",
      "Epoch [79/100], Loss: 52.6856\n",
      "Epoch [80/100], Loss: 94.8899\n",
      "Epoch [81/100], Loss: 100.5196\n",
      "Epoch [82/100], Loss: 60.3599\n",
      "Epoch [83/100], Loss: 73.2061\n",
      "Epoch [84/100], Loss: 102.9129\n",
      "Epoch [85/100], Loss: 92.5128\n",
      "Epoch [86/100], Loss: 47.5509\n",
      "Epoch [87/100], Loss: 94.2306\n",
      "Epoch [88/100], Loss: 87.8077\n",
      "Epoch [89/100], Loss: 87.1482\n",
      "Epoch [90/100], Loss: 56.4473\n",
      "Epoch [91/100], Loss: 96.1400\n",
      "Epoch [92/100], Loss: 93.4116\n",
      "Epoch [93/100], Loss: 79.3253\n",
      "Epoch [94/100], Loss: 62.8911\n",
      "Epoch [95/100], Loss: 86.1095\n",
      "Epoch [96/100], Loss: 56.9006\n",
      "Epoch [97/100], Loss: 68.4165\n",
      "Epoch [98/100], Loss: 46.7308\n",
      "Epoch [99/100], Loss: 47.0420\n",
      "Epoch [100/100], Loss: 58.3292\n"
     ]
    }
   ],
   "source": [
    "def fit(num_epochs,model,loss_fn,opt,train_dl):\n",
    "    #Repeat for given epochs\n",
    "    for i in range(num_epochs):\n",
    "        #Train with the batches of data\n",
    "        for x,y in train_dl:\n",
    "            #Generate prediction\n",
    "            pred = model(x)\n",
    "            #Calculate loss\n",
    "            loss = loss_fn(pred,y)\n",
    "            #Compute gradients\n",
    "            loss.backward()\n",
    "            #update parameters using gradients\n",
    "            opt.step()\n",
    "            #reset the gradient to zero\n",
    "            opt.zero_grad()\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(i+1, num_epochs, loss.item()))\n",
    "fit(100,model,loss_fn,opt,train_dl)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7dbbc27f-75a8-4274-8943-c905be198f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 57.7045,  72.2765],\n",
       "        [ 78.5700,  95.5735],\n",
       "        [125.1981, 141.6810],\n",
       "        [ 24.4947,  47.0259],\n",
       "        [ 93.6733, 104.5189],\n",
       "        [ 56.4256,  71.2520],\n",
       "        [ 77.7539,  94.6613],\n",
       "        [125.1372, 141.7742],\n",
       "        [ 25.7737,  48.0503],\n",
       "        [ 94.1361, 104.6311],\n",
       "        [ 56.8884,  71.3643],\n",
       "        [ 77.2911,  94.5490],\n",
       "        [126.0142, 142.5933],\n",
       "        [ 24.0319,  46.9136],\n",
       "        [ 94.9522, 105.5433]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d5260e1b-7857-480a-a0c1-c2a9ef83074c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.],\n",
       "        [ 57.,  69.],\n",
       "        [ 80., 102.],\n",
       "        [118., 132.],\n",
       "        [ 21.,  38.],\n",
       "        [104., 118.],\n",
       "        [ 57.,  69.],\n",
       "        [ 82., 100.],\n",
       "        [118., 134.],\n",
       "        [ 20.,  38.],\n",
       "        [102., 120.]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14c0b85-bd43-44af-a04d-abc12353b8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
